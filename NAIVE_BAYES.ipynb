{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#/content/drive/MyDrive/Datos.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "434xP5XujOIP",
        "outputId": "a51770c4-0ce2-4192-d407-8ea3903a8d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.class_counts = defaultdict(int)\n",
        "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
        "        self.classes = set()\n",
        "        self.total_documents = 0\n",
        "        self.vocabulary = set()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        # Limpieza.\n",
        "        text = re.sub(r'\\W', ' ', text)\n",
        "        return text.lower().split()\n",
        "\n",
        "    def train(self, documents):\n",
        "        for document, label in documents:\n",
        "            self.total_documents += 1\n",
        "            self.classes.add(label)\n",
        "            self.class_counts[label] += 1\n",
        "            for word in self.clean_text(document):\n",
        "                # Ignorar stopwords en español\n",
        "                if word not in stopwords:\n",
        "                    self.word_counts[label][word] += 1\n",
        "                    self.vocabulary.add(word)\n",
        "\n",
        "    def predict(self, document):\n",
        "        document_words = set(self.clean_text(document))\n",
        "        scores = {c: 0 for c in self.classes}\n",
        "\n",
        "        for label in self.classes:\n",
        "            for word in document_words:\n",
        "                # Aplicar suavizado de Laplace\n",
        "                scores[label] += (self.word_counts[label][word] + 1) / (self.class_counts[label] + len(self.vocabulary))\n",
        "\n",
        "            # Incluir el logaritmo de la probabilidad de la clase\n",
        "            scores[label] += self.class_counts[label] / self.total_documents\n",
        "\n",
        "        # Normalizar para evitar overflow y underflow\n",
        "        max_score = max(scores.values())\n",
        "        scores = {label: score / max_score for label, score in scores.items()}\n",
        "\n",
        "        return max(scores, key=scores.get)\n",
        "\n",
        "# Leer datos desde un archivo CSV\n",
        "train_csv_file_path = '/content/drive/MyDrive/Train_data.csv'\n",
        "test_csv_file_path = '/content/drive/MyDrive/Test_data.csv'\n",
        "\n",
        "df = pd.read_csv(train_csv_file_path)\n",
        "test_df = pd.read_csv(test_csv_file_path)\n",
        "\n",
        "# Preprocesamiento de las etiquetas para que sean 'positivo', 'neutro' o 'negativo'\n",
        "df['sentiment'] = df['sentiment'].apply(lambda x: 'positivo' if 'positivo' in x.lower() else ('neutro' if 'neutro' in x.lower() else 'negativo'))\n",
        "# Preprocesamiento de las etiquetas para que sean 'positivo', 'neutro' o 'negativo' en el conjunto de prueba\n",
        "test_df['sentiment'] = test_df['sentiment'].apply(lambda x: 'positivo' if 'positivo' in x.lower() else ('neutro' if 'neutro' in x.lower() else 'negativo'))\n",
        "\n",
        "# Crear y entrenar el clasificador\n",
        "stopwords = set(['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'una', 'su', 'al', 'es', 'lo', 'como', 'más', 'pero', 'sus'])\n",
        "classifier = NaiveBayesClassifier()\n",
        "classifier.train(zip(df['review'], df['sentiment']))\n",
        "\n",
        "# Predicciones en el conjunto de prueba\n",
        "test_predictions = [classifier.predict(test_document) for test_document in test_df['review']]\n",
        "\n",
        "# Etiquetas verdaderas en el conjunto de prueba\n",
        "true_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "for i in range(200):  # Imprimir las primeras 10 predicciones para ilustrar\n",
        "    print(f'Comentario: {test_df[\"review\"].iloc[i]}')\n",
        "    print(f'Predicción: {test_predictions[i]} - Etiqueta Verdadera: {true_labels[i]}')\n",
        "    print('\\n')\n",
        "\n",
        "# Calcular métricas\n",
        "precision = precision_score(true_labels, test_predictions, average='weighted')\n",
        "recall = recall_score(true_labels, test_predictions, average='weighted')\n",
        "f1 = f1_score(true_labels, test_predictions, average='weighted')\n",
        "\n",
        "# Imprimir métricas redondeadas a 2 decimales\n",
        "print(f'Precision: {round(precision, 4)}')\n",
        "print(f'Recall: {round(recall, 4)}')\n",
        "print(f'F1 Score: {round(f1, 4)}')\n",
        "\n"
      ],
      "metadata": {
        "id": "nr_ThNzIjKYd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}